{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "812852e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Dell'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "783ed404",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6102e35d18f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'stopwords'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "#Although this code is giving error but it successfully imports english stopwords\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40ae6b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/Users/Dell/20_newsgroups'\n",
    "LABELS = ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
    "\n",
    "def get_dataset():\n",
    "    with open('data.txt', 'w', encoding='utf8') as outfile:\n",
    "        \n",
    "#storing files labelwise...like all 'alt.theism' comes at 0 index of 'train_file_labelled' dictionary and so on\n",
    "        train_file_labelled = {}\n",
    "\n",
    "#storing each file of training data individually in 'train_file_unlabelled' dictionary without takingcare of their labels\n",
    "        train_file_unlabelled = {}\n",
    "\n",
    "#storing each file of testing data individually in 'test_file' dictionary without takingcare of their labels\n",
    "        test_file = {}\n",
    "\n",
    "#storing the labels in numeric forms in below lists for each training and testing documents\n",
    "        y_train_labelled = []\n",
    "        y_train_unlabelled = []\n",
    "        y_test = []\n",
    "        \n",
    "        k_test_idx = 0\n",
    "        k_train_unlabel_idx = 0\n",
    "        p = -1\n",
    "        unlabel_p = -1\n",
    "        \n",
    "#traversing the entire document labelwise\n",
    "        for label in LABELS:\n",
    "            dir = '%s/%s' % (BASE_DIR, label)\n",
    "            i = 0\n",
    "            p = p + 1\n",
    "\n",
    "#storing all training documents labelwise inside 'train_file_labelled' dictionary\n",
    "            train_file_labelled[label] = {}\n",
    "    \n",
    "            unlabel_p = unlabel_p + 1\n",
    "            k_train_idx = 0\n",
    "            \n",
    "            for filename in os.listdir(dir):\n",
    "                fullfilename = '%s/%s' % (dir, filename)\n",
    "                train_file_labelled[label][k_train_idx] = []\n",
    "                test_file[k_test_idx] = []\n",
    "                with open(fullfilename, 'rb') as file:\n",
    "                    if(i < 750):\n",
    "                        text = file.read().decode(errors='replace').replace('\\n','')\n",
    "                        \n",
    "#storing current text document labelwise\n",
    "                        train_file_labelled[label][k_train_idx] = text\n",
    "                        k_train_idx = k_train_idx+1\n",
    "                        y_train_labelled.append(p)\n",
    "                        i = i+1\n",
    "                \n",
    "#storing current text document but not labelwise        \n",
    "                        train_file_unlabelled[k_train_unlabel_idx] = text\n",
    "                        y_train_unlabelled.append(unlabel_p)\n",
    "                        k_train_unlabel_idx = k_train_unlabel_idx+1\n",
    "                        \n",
    "                        outfile.write('%s\\t%s\\t%s\\n' % (label, filename, text))\n",
    "                    else:\n",
    "                        text = file.read().decode(errors='replace').replace('\\n','')\n",
    "                        test_file[k_test_idx] = text\n",
    "                        y_test.append(p)\n",
    "                        k_test_idx = k_test_idx+1\n",
    "                        i = i+1\n",
    "                        outfile.write('%s\\t%s\\t%s\\n' % (label, filename, text))\n",
    "                        \n",
    "    return train_file_labelled, y_train_labelled, test_file, y_test, train_file_unlabelled, y_train_unlabelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "660bfb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_labelled, y_train_labelled, test_data, y_test, train_data_unlabelled, y_train_unlabelled = get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b10f02da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_to_word_labelled_data(data):\n",
    "    class_in_words = {}\n",
    "#         traversing each class\n",
    "    for curr_key in data.keys():\n",
    "        class_in_words[curr_key] = []\n",
    "#         traversing each folder of a class\n",
    "        for curr_key_key in data[curr_key].keys():\n",
    "            data_str = \"\"\n",
    "#             traversing single page\n",
    "            for curr_str in data[curr_key][curr_key_key]:\n",
    "                if(curr_str.isalpha()):\n",
    "                    data_str+=curr_str\n",
    "                elif(data_str != \"\"):\n",
    "                    class_in_words[curr_key].append(data_str)\n",
    "                    data_str = \"\"\n",
    "#             class_in_words[curr_key].append(data_str)\n",
    "    return class_in_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bd08f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents are dtored in the form of string of characters which needs to be converted to string of words.\n",
    "#This is being done using the below code.\n",
    "train_data_labelled_in_word = char_to_word_labelled_data(train_data_labelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7ce05ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_to_word_unlabelled_data(data):\n",
    "    class_in_words = {}\n",
    "#         traversing each class\n",
    "    for curr_key in data.keys():\n",
    "        class_in_words[curr_key] = []\n",
    "#         traversing each folder of a class\n",
    "#         for curr_key_key in data[curr_key].keys():\n",
    "        data_str = \"\"\n",
    "#             traversing single page\n",
    "        for curr_str in data[curr_key]:\n",
    "            if(curr_str.isalpha()):\n",
    "                data_str+=curr_str\n",
    "            elif(data_str != \"\"):\n",
    "                class_in_words[curr_key].append(data_str)\n",
    "                data_str = \"\"\n",
    "#             class_in_words[curr_key].append(data_str)\n",
    "    return class_in_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "016a49cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents are dtored in the form of string of characters which needs to be converted to string of words.\n",
    "#This is being done using the below code.\n",
    "test_data_in_word = char_to_word_unlabelled_data(test_data)\n",
    "train_data_unlabelled_in_word = char_to_word_unlabelled_data(train_data_unlabelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaeae2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionary_for_unlabelled_docs(data_fit):\n",
    "    result = {}\n",
    "    for curr_class in data_fit.keys():\n",
    "        for word in data_fit[curr_class]:\n",
    "            if(word not in stopwords.words('english')):\n",
    "                if(word in result.keys()):\n",
    "                    result[word] = result[word] + 1\n",
    "                else:\n",
    "                    result[word] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30ad5789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionary_for_labelled_docs(data_fit):\n",
    "    dictionary = {}\n",
    "    for curr_class in data_fit.keys():\n",
    "        dictionary[curr_class] = {}\n",
    "        for word in data_fit[curr_class]:\n",
    "            if(word not in stopwords.words('english')):\n",
    "                if(word in dictionary[curr_class].keys()):\n",
    "                    dictionary[curr_class][word] = dictionary[curr_class][word] + 1\n",
    "                else:\n",
    "                    dictionary[curr_class][word] = 1\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6692cb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dictionary for labelled training documents\n",
    "labelled_train_dictionary = dictionary_for_labelled_docs(train_data_labelled_in_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2535729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dictionary for unlabelled training documents\n",
    "unlabelled_train_dictionary = dictionary_for_unlabelled_docs(train_data_labelled_in_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e24052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting the unlabelled_train_dictionary in descending order to get first few topmost important words \n",
    "import operator\n",
    "sorted_dictionary = dict( sorted(unlabelled_train_dictionary.items(), key=operator.itemgetter(1),reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c1d8670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n_words_dictionary(modified_dictionary):\n",
    "    new_dictionary = {}\n",
    "    i = 0\n",
    "    for key in modified_dictionary.keys():\n",
    "        new_dictionary[key] = modified_dictionary[key]\n",
    "        i = i+1\n",
    "        if(i==4000):\n",
    "            break\n",
    "    return new_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dd20c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the dictionary which contains the key-value pair for top n words only\n",
    "top_n_words_dictionary = top_n_words_dictionary(sorted_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391e15ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the top n words\n",
    "final_n_words = top_n_words_dictionary.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9875475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_single_doc_word_count(doc):\n",
    "    word_count = {}\n",
    "    for label_word in final_n_words:\n",
    "        for word in doc:\n",
    "            if(word == label_word):# and (word in final_words)):\n",
    "                if(word in word_count.keys()):\n",
    "                    word_count[word] = word_count[word]+1\n",
    "                else:\n",
    "                    word_count[word] = 1\n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da6b18c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_word_count(unlabelled_data):\n",
    "    count_word = {}\n",
    "    for i in range(len(unlabelled_data)):\n",
    "        count_word[i] = {}\n",
    "        count_word[i] = find_single_doc_word_count(unlabelled_data[i])\n",
    "    return count_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47d1afc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the word counts for each documents in train_data_labelled_in_word \n",
    "train_each_labelled_doc_dict = doc_word_count(train_data_labelled_in_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad2304cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_2d_array(data_each_dict):\n",
    "    array = []\n",
    "    i = 0\n",
    "    for key in data_each_dict.keys():\n",
    "        temp = []\n",
    "        for word in final_n_words:\n",
    "#             array[i] = []\n",
    "#             for single_word in train_each_doc_dict[key].keys():\n",
    "            if(word in data_each_dict[key].keys()):\n",
    "                temp.append(data_each_dict[key][word])\n",
    "            else:\n",
    "                temp.append(0)\n",
    "        array.append(temp)\n",
    "        i = i+1\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a8c7df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the train data into 2d array\n",
    "train_array = convert_to_2d_array(train_each_labelled_doc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "125e17c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the word counts for each documents in test_data_in_word\n",
    "test_each_doc_dict = doc_word_count(test_data_in_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be3d029b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the test data into 2d array\n",
    "test_array = convert_to_2d_array(test_each_doc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e544cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X_data(dictnry,final_dictnry):\n",
    "    curr_row = 0\n",
    "    rows, cols = (20, 4000)\n",
    "    X = [[0 for i in range(cols)] for j in range(rows)]\n",
    "    for dictnry_key in dictnry.keys():\n",
    "        curr_col = 0\n",
    "        for key in final_dictnry.keys():\n",
    "            if key in dictnry[dictnry_key].keys():\n",
    "                X[curr_row][curr_col] = dictnry[dictnry_key][key]\n",
    "            curr_col = curr_col + 1\n",
    "        curr_row = curr_row + 1\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "938f1b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the below code will create a 2d list which contains count of top n words for each documents\n",
    "xtrain = create_X_data(labelled_train_dictionary,top_n_words_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f00579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "xtrain = np.array(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e89200b9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05952193, 0.06184959, 0.04876875, ..., 0.04201681, 0.05042017,\n",
       "        0.04201681],\n",
       "       [0.04886323, 0.04111205, 0.05206222, ..., 0.04201681, 0.05042017,\n",
       "        0.02521008],\n",
       "       [0.0476954 , 0.0822241 , 0.04699534, ..., 0.05042017, 0.01680672,\n",
       "        0.01680672],\n",
       "       ...,\n",
       "       [0.05338623, 0.06667473, 0.0594852 , ..., 0.18487395, 0.07563025,\n",
       "        0.1512605 ],\n",
       "       [0.05748288, 0.0553001 , 0.05953587, ..., 0.04201681, 0.11764706,\n",
       "        0.06722689],\n",
       "       [0.05896583, 0.05666142, 0.06614816, ..., 0.03361345, 0.02521008,\n",
       "        0.11764706]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the probability of each word for each document in xtrain and storing in a 2d numpy array xtrain_probability\n",
    "xtrain_probability = xtrain / xtrain.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdcfb648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_doc_class(doc,xtrain_probability,final_dictionary):\n",
    "    i = 0\n",
    "    max_prob = -1\n",
    "    prob = [0 for i in range(20)]\n",
    "    for this_class in LABELS:\n",
    "        k = 0\n",
    "#         prob.append(0)\n",
    "        for this_word in final_dictionary.keys():\n",
    "            if this_word in doc:\n",
    "                prob[i] += xtrain_probability[i][k]\n",
    "            k = k+1\n",
    "        if(prob[i]>max_prob):\n",
    "            max_prob = prob[i]\n",
    "            resultant_class = i\n",
    "        i = i+1\n",
    "    return resultant_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b231229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_all_doc(data):\n",
    "    ypredict = []\n",
    "    for this_doc in data.keys():\n",
    "        ypredict.append(predict_single_doc_class(np.array(test_data_final[this_doc]),xtrain_probability,top_n_words_dictionary))\n",
    "    return ypredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a44fe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting the classess for each test document\n",
    "ypredicted = predict_all_doc(test_data_in_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b6b47d2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8fd983942ce1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mypredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mypredicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mytest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Classification Report Using Own code from Scratch\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mypredicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "ypredicted = np.array(ypredicted)\n",
    "ytest = np.array(y_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(\"Classification Report Using Own code from Scratch\")\n",
    "print(classification_report(ytest, ypredicted))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(ytest, ypredicted))\n",
    "print()\n",
    "print(\"Accuracy Score\")\n",
    "print(accuracy_score(ytest, ypredicted) * 100, \"%\", sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0bddf4",
   "metadata": {},
   "source": [
    "<!--Result for #top_words = 4000 using manual implemenatation without sklearn is as follows:-->\n",
    "Classification Report\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.75      0.77      0.76       250\n",
    "           1       0.94      0.78      0.85       250\n",
    "           2       0.61      0.99      0.76       250\n",
    "           3       0.88      0.89      0.89       250\n",
    "           4       0.99      0.85      0.92       250\n",
    "           5       0.90      0.84      0.87       250\n",
    "           6       0.97      0.74      0.84       250\n",
    "           7       0.98      0.82      0.89       250\n",
    "           8       1.00      0.86      0.92       250\n",
    "           9       0.99      0.88      0.93       250\n",
    "          10       0.93      0.98      0.95       250\n",
    "          11       0.77      0.98      0.86       250\n",
    "          12       0.99      0.56      0.71       250\n",
    "          13       1.00      0.83      0.91       250\n",
    "          14       0.94      0.94      0.94       250\n",
    "          15       0.94      1.00      0.97       247\n",
    "          16       0.82      0.85      0.84       250\n",
    "          17       0.63      0.99      0.77       250\n",
    "          18       0.60      0.75      0.67       250\n",
    "          19       0.69      0.53      0.60       250\n",
    "\n",
    "    accuracy                           0.84      4997\n",
    "   macro avg       0.87      0.84      0.84      4997\n",
    "weighted avg       0.87      0.84      0.84      4997\n",
    "\n",
    "Confusion Matrix\n",
    "[[192   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   8\n",
    "    5  44]\n",
    " [  2 194  22   1   0  10   0   0   0   0   0   8   0   0   2   0   0   5\n",
    "    6   0]\n",
    " [  0   0 248   0   0   2   0   0   0   0   0   0   0   0   0   0   0   0\n",
    "    0   0]\n",
    " [  2   2  17 222   0   3   0   0   0   0   0   2   0   0   0   0   0   2\n",
    "    0   0]\n",
    " [  0   0   8   9 213   0   2   0   0   0   0   2   0   0   0   0   0  10\n",
    "    6   0]\n",
    " [  0   3  33   1   0 211   0   0   0   0   0   1   0   0   0   0   0   0\n",
    "    1   0]\n",
    " [  0   0  28  11   1   1 185   1   0   2   1   4   1   0   1   0   1   5\n",
    "    7   1]\n",
    " [  0   1   9   0   0   2   2 204   1   1   0   2   0   0   1   0   4   4\n",
    "   19   0]\n",
    " [  0   0  10   0   0   0   1   2 214   0   0   2   0   0   0   0   2  13\n",
    "    5   1]\n",
    " [  0   0   5   0   0   0   0   0   0 221  11   0   0   0   0   1   0   6\n",
    "    6   0]\n",
    " [  0   0   3   0   0   0   0   0   0   0 244   1   0   0   1   0   0   0\n",
    "    1   0]\n",
    " [  0   0   2   0   0   0   0   0   0   0   0 245   0   0   1   0   1   0\n",
    "    1   0]\n",
    " [  1   2  13   7   0   2   0   2   0   0   1  43 139   1   6   0   3  24\n",
    "    6   0]\n",
    " [ 10   3   4   0   0   2   0   0   0   0   2   2   0 208   1   0   0   7\n",
    "   11   0]\n",
    " [  1   1   0   0   1   0   0   0   0   0   0   0   0   0 235   0   0   5\n",
    "    7   0]\n",
    " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 247   0   0\n",
    "    0   0]\n",
    " [  0   0   0   0   0   0   0   0   0   0   0   4   0   0   0   0 213  13\n",
    "   18   2]\n",
    " [  0   0   1   0   0   0   0   0   0   0   0   1   0   0   0   1   0 247\n",
    "    0   0]\n",
    " [  0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0  27  23\n",
    "  188  10]\n",
    " [ 47   0   1   0   0   0   0   0   0   0   0   3   0   0   1  13   9  17\n",
    "   27 132]]\n",
    "\n",
    "Accuracy Score\n",
    "84.09045427256355%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e0c10b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(train_array,y_train_unlabelled)\n",
    "ypred_sk = clf.predict(test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2ddd3bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.68      0.72       250\n",
      "           1       0.70      0.75      0.73       250\n",
      "           2       0.91      0.34      0.50       250\n",
      "           3       0.61      0.84      0.71       250\n",
      "           4       0.77      0.92      0.84       250\n",
      "           5       0.84      0.77      0.80       250\n",
      "           6       0.73      0.91      0.81       250\n",
      "           7       0.86      0.88      0.87       250\n",
      "           8       0.90      0.95      0.92       250\n",
      "           9       0.92      0.92      0.92       250\n",
      "          10       0.96      0.92      0.94       250\n",
      "          11       0.95      0.88      0.91       250\n",
      "          12       0.74      0.83      0.78       250\n",
      "          13       0.96      0.77      0.86       250\n",
      "          14       0.91      0.90      0.91       250\n",
      "          15       0.94      1.00      0.97       247\n",
      "          16       0.83      0.89      0.86       250\n",
      "          17       0.90      0.89      0.90       250\n",
      "          18       0.82      0.71      0.76       250\n",
      "          19       0.62      0.67      0.64       250\n",
      "\n",
      "    accuracy                           0.82      4997\n",
      "   macro avg       0.83      0.82      0.82      4997\n",
      "weighted avg       0.83      0.82      0.82      4997\n",
      "\n",
      "[[169   0   0   0   0   0   3   4   1   0   0   0   5   0   1   2   0   1\n",
      "    1  63]\n",
      " [  1 188   1   7  14   9   8   1   2   1   0   7   5   0   6   0   0   0\n",
      "    0   0]\n",
      " [  0  24  86  89  18  21   4   0   1   0   0   0   7   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   4   1 211  19   4   5   0   0   0   0   0   5   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   0   8 229   0  11   0   0   0   0   0   0   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0  26   3  12   6 193   3   0   3   1   0   0   0   1   2   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   8   0   0 228   1   1   1   1   0   8   1   1   0   0   0\n",
      "    0   0]\n",
      " [  0   0   2   2   1   1   8 221   4   1   2   0   6   0   1   0   0   0\n",
      "    1   0]\n",
      " [  0   0   0   1   0   0   9   2 237   0   0   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   1   0   1   0   6   2   4 229   4   0   0   1   0   0   2   0\n",
      "    0   0]\n",
      " [  0   0   0   0   1   0   3   0   2  10 231   0   0   0   3   0   0   0\n",
      "    0   0]\n",
      " [  0   5   0   0   0   2   4   1   3   1   0 220  11   0   1   0   2   0\n",
      "    0   0]\n",
      " [  0   7   0   7   2   1   3   4   0   0   0   1 207   1   3   0   0   9\n",
      "    5   0]\n",
      " [  0   5   0   0   4   0  12   7   2   4   2   1  18 193   1   0   0   0\n",
      "    1   0]\n",
      " [  0   5   0   0   1   0   1   2   0   0   0   0   5   4 226   0   0   0\n",
      "    6   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 247   0   0\n",
      "    0   0]\n",
      " [  0   0   0   1   1   0   1   7   0   0   0   2   0   0   0   0 222   0\n",
      "    5  11]\n",
      " [  5   1   0   0   1   0   1   2   3   0   0   1   0   0   1   4   2 222\n",
      "    4   3]\n",
      " [  0   1   0   0   0   0   1   1   0   0   0   0   1   0   0   0  31  12\n",
      "  177  26]\n",
      " [ 43   1   0   0   0   0   1   1   0   0   0   0   0   0   1   9   9   2\n",
      "   16 167]]\n",
      "0.821092655593356\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(\"Classification Report Using Sklearn Multinomial NaiveBayes\")\n",
    "print(classification_report(y_test,ypred_sk))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test,ypred_sk))\n",
    "print()\n",
    "print(\"Accuracy Score\")\n",
    "print(accuracy_score(y_test,ypred_sk))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50296bd8",
   "metadata": {},
   "source": [
    "<!--Result for #top_words = 4000 using sklearn is as follows:-->\n",
    "Classification Report\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.77      0.68      0.72       250\n",
    "           1       0.70      0.75      0.73       250\n",
    "           2       0.91      0.34      0.50       250\n",
    "           3       0.61      0.84      0.71       250\n",
    "           4       0.77      0.92      0.84       250\n",
    "           5       0.84      0.77      0.80       250\n",
    "           6       0.73      0.91      0.81       250\n",
    "           7       0.86      0.88      0.87       250\n",
    "           8       0.90      0.95      0.92       250\n",
    "           9       0.92      0.92      0.92       250\n",
    "          10       0.96      0.92      0.94       250\n",
    "          11       0.95      0.88      0.91       250\n",
    "          12       0.74      0.83      0.78       250\n",
    "          13       0.96      0.77      0.86       250\n",
    "          14       0.91      0.90      0.91       250\n",
    "          15       0.94      1.00      0.97       247\n",
    "          16       0.83      0.89      0.86       250\n",
    "          17       0.90      0.89      0.90       250\n",
    "          18       0.82      0.71      0.76       250\n",
    "          19       0.62      0.67      0.64       250\n",
    "\n",
    "    accuracy                           0.82      4997\n",
    "   macro avg       0.83      0.82      0.82      4997\n",
    "weighted avg       0.83      0.82      0.82      4997\n",
    "[[169   0   0   0   0   0   3   4   1   0   0   0   5   0   1   2   0   1\n",
    "    1  63]\n",
    " [  1 188   1   7  14   9   8   1   2   1   0   7   5   0   6   0   0   0\n",
    "    0   0]\n",
    " [  0  24  86  89  18  21   4   0   1   0   0   0   7   0   0   0   0   0\n",
    "    0   0]\n",
    " [  1   4   1 211  19   4   5   0   0   0   0   0   5   0   0   0   0   0\n",
    "    0   0]\n",
    " [  0   1   0   8 229   0  11   0   0   0   0   0   0   0   1   0   0   0\n",
    "    0   0]\n",
    " [  0  26   3  12   6 193   3   0   3   1   0   0   0   1   2   0   0   0\n",
    "    0   0]\n",
    " [  0   0   0   8   0   0 228   1   1   1   1   0   8   1   1   0   0   0\n",
    "    0   0]\n",
    " [  0   0   2   2   1   1   8 221   4   1   2   0   6   0   1   0   0   0\n",
    "    1   0]\n",
    " [  0   0   0   1   0   0   9   2 237   0   0   0   1   0   0   0   0   0\n",
    "    0   0]\n",
    " [  0   0   1   0   1   0   6   2   4 229   4   0   0   1   0   0   2   0\n",
    "    0   0]\n",
    " [  0   0   0   0   1   0   3   0   2  10 231   0   0   0   3   0   0   0\n",
    "    0   0]\n",
    " [  0   5   0   0   0   2   4   1   3   1   0 220  11   0   1   0   2   0\n",
    "    0   0]\n",
    " [  0   7   0   7   2   1   3   4   0   0   0   1 207   1   3   0   0   9\n",
    "    5   0]\n",
    " [  0   5   0   0   4   0  12   7   2   4   2   1  18 193   1   0   0   0\n",
    "    1   0]\n",
    " [  0   5   0   0   1   0   1   2   0   0   0   0   5   4 226   0   0   0\n",
    "    6   0]\n",
    " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 247   0   0\n",
    "    0   0]\n",
    " [  0   0   0   1   1   0   1   7   0   0   0   2   0   0   0   0 222   0\n",
    "    5  11]\n",
    " [  5   1   0   0   1   0   1   2   3   0   0   1   0   0   1   4   2 222\n",
    "    4   3]\n",
    " [  0   1   0   0   0   0   1   1   0   0   0   0   1   0   0   0  31  12\n",
    "  177  26]\n",
    " [ 43   1   0   0   0   0   1   1   0   0   0   0   0   0   1   9   9   2\n",
    "   16 167]]\n",
    "Accuracy: 0.821092655593356 = 82.10 %\n",
    "\n",
    "Therefore manual implementation gives better result than using sklearn "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
